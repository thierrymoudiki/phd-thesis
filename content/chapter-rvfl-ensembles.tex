% !TEX root = ../thesis-example.tex
%
\chapter{Multiple time series forecasting using ensembles of quasi-randomized functional link neural networks}
\label{sec:rvfl_ensembles}

\section{Introduction}

The goal of ensemble learning is to combine two or more individual statistical/machine learning models - the base models or base learners - into one, in order to obtain an ensemble model, with an improved out-of-sample error over the base models.

\medskip

Ensemble learning is widely used in the winning solutions of machine learning competitions. It allows to achieve very good performances indeed, at the expense of being relatively less interpretable than the base learners.

\medskip

As a consequence, choosing to use ensemble models or a base model for solving a given problem, could sometimes be seen as finding a trade-off between the desire for interpretability and the desire for an highly increased performance. That said, some techniques such as variable importance for ensemble of trees, can give a sense of which predictor contributes the most to the perfomance of the model.

\medskip

In this paper, we apply three popular ensemble learning methods to multiple time series forecasting: Bootstrap aggregating (cite Efron), known as bagging, and stacked generalization(cite Wolpert), known as stacking. The base learners that we use, are the quasi-random vector functional link neural networks introduced in Moudiki et al. (2017).

\medskip

In the next section, we give an overview of the base learners. Then, we describe how we use these models as the basic components of our bagged/stacked ensembles. To finish, we present some numerical examples of use of these new models for forecasting multiple time series.

\section{Description of the base models}
\label{sec:basemodeldesc}

The base learner is described in lengths in Moudiki et al. (2017). It is a single layer feed forward neural networks (SLFN). We have an output variable $y \in \RR^n$, which has to be explained by a set of observed predictors $X^{(j)} \in \RR^n$, $j \in \left\lbrace 1, \ldots,
p\right\rbrace$. The RVFL networks that we use to explain $y$ is described for $i \in \left\lbrace 1, \ldots, n\right\rbrace$ as:
$$
y_i = \beta_0 + \sum_{j = 1}^p \beta_j X_i^{(j)} + \sum_{l = 1}^L \gamma_l \:
g\left(\sum_{j = 1}^p W^{(j, l)} X_i^{(j)}\right) + \epsilon_i
$$

\medskip

Where $g$ is the \textit{activation function}, $L$ the number of nodes in the hidden
layer, $W^{(j, l)}$ are elements of the hidden layer, and the parameters
$\beta_j$ and $\gamma_l$ are to be learned from the observed data $X^{(j)}, \: j
\in \left\lbrace 1, \ldots, p\right\rbrace$. The $\epsilon_i$'s are the residual
differences between the output variable values and the RVFL model.

\medskip

This type of model can be seen as a one explaining $y_i$, by finding a
compromise between linear and potentially non-linear effects of the original
predictors $X^{(j)}$ and transformed predictors
$$
\Phi(\bfX)^{(l)}= g\left(\sum_{j = 1}^p W^{(j, l)} X_i^{(j)}\right)
$$
$\left \lbrace 1, \ldots, L\right\rbrace$ on the response. In this paper, we use the Rectified Linear Units activation function, known as ReLU
$$
g: \: x \mapsto max(x, 0)
$$
But other choices of activation functions, such as the sigmoid function or the hyperbolic tangent (or others) can be envisaged.

\medskip

The elements $W^{(j, l)}$ of the hidden layer are taken from a quasi-random (deterministic) \textit{sobol} sequence on $[0, 1]$, which is shifted in such a way that they belong to $[-1, 1]$. Solving for the optimal $\beta_j$'s and $\gamma_l$'s is done by searching these parameters,  in restricted regions where we have:
$$
\sum_{j=1}^p \beta_j^2  \leq u
$$
and
$$
\sum_{l=1}^L
\gamma_l^2 \leq v
$$ for $u, v \in \RR^*$. That is, by applying a regularization to these unknown parameters.


\medskip

Now, if we consider $p \in \mathbb{N}^*$ time series $(X_t^{(j)})_{t \geq 0}, j = 1, \ldots, p$,
observed at $n \in \mathbb{N}^*$ discrete dates. We are interested in
obtaining simultaneous forecasts of the $p$ time series at time $n+h$, $h \in
\mathbb{N}^*$, by allowing each of the $p$ variables to be influenced by the
others. We use $k < n$ lags of each of the observed $p$ time
series. So that, the output variables to be explained are:

\begin{equation}
Y^{(j)} = \left(X^{(j)}_n, \ldots, X^{(j)}_{k+1} \right)^T
\end{equation}

for $j \in \left\lbrace 1, \ldots,
p \right\rbrace$. Where $X^{(j)}_n$ is the most contemporaneous observed value
of the $j^{th}$ time series, and $X^{(j)}_{k+1}$ was observed $k$ dates earlier
in time for $(X^{(j)}_t)_{t \geq 0}$. These output variables are stored in a
matrix: $$ \bfY \in \RR^{(n-k) \times p} $$ and the predictors are
stored in a matrix: $$ \bfX \in \RR^{(n-k) \times (k \times p)} $$
where $\bfX$ consists in $p$ blocks of $k$ lags, for each one of the observed
$p$ time series.

\medskip

An additional layer of transformed  predictors
is added to $\bfX$, in order to capture the potentially non-linear
interactions between the predictors and the output variable. Adding the transformed predictors to the original ones, leads to a new matrix of predictors with dimensions $(n-k) \times (k \times p + L)$, where $L$ is the number of nodes in the hidden layer.

\medskip

For example, we have $p = 2$ time series $(X^{(1)}_{t_1}, \ldots,  X^{(1)}_{t_5})$ and $(X^{(2)}_{t_1}, \ldots,  X^{(2)}_{t_5})$ observed at $n = 5$ dates $t_1 < \ldots < t_5$, with $k = 2$ lags, and $L = 3$ nodes in the hidden layer. In this case, the response variables are stored in:
$$
\bfY = \left( {\begin{array}{cc} X^{(1)}_{t_5} &  X^{(2)}_{t_5}\\ X^{(1)}_{t_4} & X^{(2)}_{t_4} \\ X^{(1)}_{t_3} & X^{(2)}_{t_3}\      \end{array} } \right)
$$
The predictors are stored in:
$$
\bfX = \left( {\begin{array}{cccc} X^{(1)}_{t_4} & X^{(1)}_{t_3} & X^{(2)}_{t_4} & X^{(2)}_{t_3} \\ X^{(1)}_{t_3} & X^{(1)}_{t_2} & X^{(2)}_{t_3} & X^{(2)}_{t_2} \\ X^{(1)}_{t_2} & X^{(1)}_{t_1} & X^{(2)}_{t_2} & X^{(2)}_{t_1} \      \end{array} }\right)
$$
And the coefficients in the hidden layer are:
$$
\textbf{W} = \left( {\begin{array}{ccc} W^{(1, 1)} & W^{(1, 2)} & W^{(1, 3)}  \\ W^{(2, 1)} & W^{(2, 2)} & W^{(2, 3)}  \\ W^{(3, 1)} & W^{(3, 2)} & W^{(3, 3)} \\ W^{(4, 1)} & W^{(4, 2)} & W^{(4, 3)}  \      \end{array} }\right)
$$

\medskip

We let $y$ be the $j_0^{th}$ column (out of $p$) of the response matrix $\bfY$, and $\Phi(\bfX)$ be the matrix of transformed predictors obtained from $\bfX$ by the hidden layer. We also denote the set of regression parameters associated with this $j_0^{th}$ time series, as:
$$
\beta_m^{(j_0)} =: \beta_m
$$
and
$$
\gamma_l^{(j_0)} =: \gamma_l
$$

for $m \in \left\lbrace 1, \ldots, k \right\rbrace$; $l \in \left\lbrace 1, \ldots,  L\right\rbrace$. Solving for the regression parameters for the $j_0^{th}$ time series, under the constraints
$$
\sum_{m=1}^{k\times p} \beta_m^2 \leq u
$$
and
$$
\sum_{l=1}^L \gamma_l^2 \leq v
$$
for $u, v \in \RR^*$, leads to minimizing a penalized residual sum of squares:
$$
\mathcal{L}(\bfX; \beta, \gamma) = \left(y - \bfX\beta -
\Phi(\bfX)\gamma\right)^T\left(y - \bfX\beta - \Phi(\bfX)\gamma\right) + \lambda_1
\beta^T \beta + \lambda_2 \gamma^T\gamma
$$

\medskip

where $\lambda_1$ and $\lambda_2$ are Lagrange multipliers. Now, by denoting:

$$ A = \left( {\begin{array}{cc} \bfX^T\bfX + \lambda_1 I_{k\times p} &  \bfX^T\Phi(\bfX)\\
\Phi(\bfX)^T\bfX & \Phi(\bfX)^T\Phi(\bfX) + \lambda_2 I_{L} \      \end{array} } \right) =:
\left( {\begin{array}{cc} B &  C^T\\ C & D \      \end{array} } \right) $$

and $S = D - CB^+C^T$. And:

$$
A^+ = \left( {\begin{array}{cc} B^+ + B^+ C^T
S^+ CB^+  &  -B^+ C^T S^+\\ -S^+CB^+ & S^+ \      \end{array} } \right) =:
\left( {\begin{array}{cc} A_1^+  &  A_2^+\\ A_3^+ & A_4^+ \      \end{array} }
\right)
$$


where $S^+$ and $B^+$ are the Moore-Penrose pseudo-inverse of matrices $S$ and
$B$. The whole set of parameters, for all the $p$ observed time series is given by:

$$
\left( {\begin{array}{c} \bm{\hat{\beta}} \\       \bm{\hat{\gamma}} \      \end{array}
} \right) := \left( {\begin{array}{cc} A_1^+  &  A_2^+\\ A_3^+ & A_4^+ \      \end{array}
} \right)\left( {\begin{array}{c} \bfX^T\bfY \\       \Phi(\bfX)^T\bfY \      \end{array} }
\right)
$$

\section{Ensembles of RVFL}
\label{sec:ensemblemethods}

As mentioned in the introduction, we will use bagging, and stacking to construct ensembles of RVFL from the previous section \ref{sec:basemodeldesc}. These   techniques will be described in the next sections ~\ref{sec:rvflbagging} and \ref{sec:rvflstacking}. Firstly in a general context, and secondly as how they are applied to our RVFL models.


\subsection{Bagging}
\label{sec:rvflbagging}

The Bootstrap (cite Efron) uses multiple random replications of a given data set, to obtain standard errors of model parameters, for example. In the context of ensemble learning, these replications of the original data set are used to produce various predictions of the base models, which are then aggregated - in the case of regression problems, they are averaged, and in the case of classification problems, majority vote could be used - to obtain a single prediction with less out-of-sample variance. This procedure is called bootstrap aggregating or \textit{bagging}.

\medskip

In order to illustrate the benefits of the bagging, we consider $n$ different base learners, with out-of-sample prediction errors equal to $\epsilon_1, \ldots, \epsilon_n$, and assume that the distribution of these errors are centered around $0$:
$$
\EE \left[ \epsilon_i\right] = 0
$$
for $i = 1, \ldots, n$. In addition, we have:
$$
\EE \left[ \epsilon_i \epsilon_j\right] = \gamma
$$
for $i \neq j$; that is, the covariance between the errors is equal to $\gamma$. And:
$$
Var(\epsilon_i) = \sigma^2
$$
for $i = 1, \ldots, n$. The out-of-sample mean squared error (MSE) of the aggregated (averaged) model including these $n$ base models is equal to:

\begin{eqnarray*}
MSE = \EE\left[ \left( \frac{1}{n} \sum_{i = 1}^n \epsilon_i \right)^2 \right] &=& \frac{1}{n^2} \EE\left[ \left( \sum_{i = 1}^n \epsilon_i \right)^2 \right]\\
 &=& \frac{1}{n^2} \EE\left[ \sum_{i = 1}^n \epsilon_i^2 + 2 \sum_{i < j} \epsilon_i \epsilon_j  \right]\\
 &=& \frac{1}{n^2} \left( \sum_{i = 1}^n \EE\left[\epsilon_i^2\right] + 2 \sum_{i < j} \EE\left[\epsilon_i \epsilon_j  \right] \right)\\
 &=& \frac{1}{n^2} \left( n \sigma^2 + 2 \frac{n(n-1)}{2} \gamma \right)\\
 &=& \frac{\sigma^2}{n} + \frac{(n-1)}{n} \gamma \\
\end{eqnarray*}

From this expression of the $MSE$, we can observe that if $n$ is high ($n \rightarrow \infty$), that is, if there are several base learners in the ensemble, and the out-of-sample expected error is low, the out-of-sample MSE of the ensemble prediction will decrease, and can eventually be reduced to $\gamma$. If, in addition, the model predictions are perfectly uncorrelated, i.e $\gamma ~= 0$, then the out-of-sample MSE is further decreased.

\medskip

Having a low value for $\gamma$, along with a low out-of-sample expected error, helps in achieving a lower out-of-sample prediction error for the ensemble model. Decorrelation in ensemble learning is hence important, and consists in increasing the diversity in the base learners, in order to obtain a low value for $\gamma$.

\medskip

This decorrelation among the base learners is achieved for example in Random Forest models (cite Breiman, L. (2001)), by growing each tree in the forest, with only a subset of the predictors available. Also, an example of use of decorrelation, specifically for ensembles of neural networks is demonstrated in (cite Rosen (1996)). The author presents three approaches for achieving \textit{disagreement} between the networks: one in which they are trained independently and aggregated with the hope that their predictions are somewhat different; a second one, in which different activation functions or achitecture (typically, more or less hidden layers or nodes in the hidden layers etc.) for each base learner. A third approach consists in training the individual networks on different subsamples of the original training set. The case of decorrelation learning for RVFL is treated in (cite Alamdoosh et Wang (2014))

\medskip

In both papers, (cite Rosen (1996)) and (cite Alamdoosh et Wang (2014)), the procedure implemented in order to obtain a decorrelation of the base learners is denoted as Negative Correlation Learning (NCL). The general idea is to minimize the penalized Root Mean Squared Error:
$$
\sum_{i = 1}^n\left[\left(y_i - f_k(\textbf{x}_i)\right)^2 + \lambda p_k(\textbf{x}_i)\right]
$$
where $\textbf{x}_i \in \RR^p$ is the $i^{th}$ observation of the training data set, with $p$ features. $f_k$ is a base learner with $k \in \left \lbrace 1 \ldots B\right \rbrace$, and $B$ is the number of bootstrap resamples. $p_k$ is a penalty term decorrelating the current network's error with the errors of the networks previously trained. $\lambda$ is a Lagrange multiplier, a regularization parameter, preventing the correlation between the successive base learners in-sample errors from being high. For example, $p_k$ could be defined as:
$$
p_k(\textbf{x}_i) = \left(y_i - f_k(\textbf{x}_i)\right)\sum_{j < k}\left(y_i - f_j(\textbf{x}_i)\right)
$$

\medskip

In this chapter, we use the third approach described in (cite Rosen (1996))  (although many other approaches can be envisaged). Multiple samples (training) data sets are constructed by randomly picking a fraction \code{col\underline{ }sample\underline{ }coeff} of the covariates, and a subset (using the fraction \code{row\underline{ }sample\underline{ }coeff}) of the lines, as described in figure \ref{bootstrap_resampling_plot} (using notations from section \ref{sec:basemodeldesc}). Taking a subset of the lines is done by respecting the serial dependence of the series and taking consecutive observations (that is, without skipping any observation) for each bootstrap resample. The predictions associated to each training set resample are then averaged, in order to obtain a single prediction, with a confidence interval around it. Some numerical examples on the application of bagging to RVFL base learners can be found in section \ref{sec:numericalexamples}

\begin{figure}[!htb]
\centering
\includegraphics[width=12cm]{gfx/chapter-rvfl-ensembles/bootstrap_resampling.png}
\caption{Construction of $B$ bootstrap resamples by using the initial data}
\label{bootstrap_resampling_plot}
\end{figure}

% \subsection{Boosting}
% \label{sec:rvflboosting}
% 
% The boosting approach is described in details in (cite Friedman (2001)). The general idea of this algorithm is to learn the in-sample residuals of the base-learners iteratively, but to stop learning them before the out-of-sample error starts to worsen. 
% 
% The boosting algorithm that is used in this chapter, is the one described in (cite Friedman (2001)). It is adapted as follows, for an observation of the response variable $y_i$, and predictors stored in \textbf{x}$_i$, for $i \in \left\lbrace 1, \ldots, n \right\rbrace$: 
% 
% $F_0(\textbf{x}) = \bar{y}$ or $F_0(\textbf{x}) = y_{(n/2)}$\\
% For $b = 1$ to $B$ do\\
% $\: \tilde{y}_i = y_i - F_{b-1}\left( \textbf{x}_i\right)$\\
% $(\rho_b, \lambda_{1, b}, \lambda_{2, b}) = ArgMin_{\rho, \lambda_1, \lambda_2}\sum_{i = 1}^n \left[\tilde{y}_i - \nu \rho h(\textbf{x}_i, \lambda_1, \lambda_2]\right)^2$\\
% $F_b(\textbf{x}) = F_{b-1}(\textbf{x}) + \nu \rho_b h(\textbf{x}, \lambda_{1, b}, \lambda_{2, b})$\\
% endFor\\
% end Algorithm
% 
% In this algorithm, the base-learner is denoted as $h(\textbf{x}, \lambda_{1}, \lambda_{2})$, and is an RVFL model for multiple time series, as described in previous sections, with $2$ nodes in the hidden layer (because we do not want to learn too much of the residuals at each boosting iteration). $\lambda_1$ and  $\lambda_2$ are the two regularization parameters of the algorithm, as also described in the previous sections. In particular, $\nu$ is a parameter (an hyperparameter) called the learning rate, which prevents the algorithm from doing too large steps when learning the residuals.
% 
% We use the same number of boosting iterations and learning rate for all the observed time series. Which is probably 

\subsection{Stacking}
\label{sec:rvflstacking}

Stacked generalization or stacking, was introduced (cite Wolpert (1992)). It is also presented in (Breiman (2001)) for regression models. The idea behind this procedure is to construct new predictors for the training data set, by using diverse predictions of multiple models, which are combined by a meta-learner model. A simple example of 2-fold stacking applied to regression is described hereafter. It is possible to imagine examples with more stacked layers:

\begin{itemize}
\item Divide the original training data set $\textbf{X} \in \RR^{n \times p}$, into two parts: \code{part1} and \code{part2}, each with $n/2$ rows
\item Train a base learner model on \code{part1} and obtain $n/2$ predictions on \code{part2}.
\item Train the same base learner model on \code{part2} and obtain $n/2$ predictions on \code{part1}.
\item Train a  meta-learner model on the new data set \code{part3}, consisting in the the original predictors, plus the predictors constructed by applying the base learner model on \code{part1} and \code{part2}.
\end{itemize}
\medskip

Typically, in this procedure, various types of base learners are used, to increate the diversity of new predictors. Since we are using time series data here, which inherently exhibit a serial dependence between the observations, we have to adapt the procedure described previously. In the case of a 2-fold stacking again, we divide the original training data set  $\textbf{X} \in \RR^{n \times p}$ (with $p$ time series observed at $n$ dates) into two parts: \code{part1} and \code{part2}; each consisting of $n/2$ rows. \code{part1} contains the most ancient observations and \code{part2}, the most recent observations of the time series contained in $\textbf{X}$. Also, we use multiple resamples of the base learner, as follows (this procedure is also described in figure \ref{rvfl_stacking_plot}):

\begin{itemize}
\item Train $B$ resampled RVFL models on \code{part1}, using a random subset of \code{part1} in each resampling iteration. Obtain $B$ sets of predictions ($B \times p$ new predictors) with these models, over the whole horizon  of \code{part2}.
\item Create a new enriched data set \code{part3}, containing the observed time series from \code{part2}, and the $B \times p$ additional series predicted from \code{part1} on \code{part2}.
\item Use a meta-learner to obtain predictions on the new, enriched dataset, \code{part3}.
\end{itemize}

\newpage

\begin{figure}[!htb]
\centering
\includegraphics[width=14cm]{gfx/chapter-rvfl-ensembles/rvfl_stacking.png}
\caption{Construction of the enriched/stacked dataset}
\label{rvfl_stacking_plot}
\end{figure}


For the latter point, we consider a few meta-learner models that have been used in the past in the literature (cite Breiman's Stacked Regressions). In general, the idea is that a relatively simple meta-learner will achieve a good performance. We use the following models for this purpose:
\begin{itemize}
\item Linear \textbf{least squares regression} model
\item Linear least squares regression model \textbf{with positive coefficients} (cite Lawson CL, Hanson RJ (1974)) and Lawson CL, Hanson RJ (1995), as used in (cite Breiman (2001))
\item \textbf{Ridge regression} with the use of singular values of $\ldots$ (cite Hoerl et Kennard 1970)
\end{itemize}

These selected meta-learners are trained on \code{part3}, with the most contemporaneous observations of the series as responses, and their respective lags as predictors. Some numerical examples on the application of stacking to RVFL base learners can be found in section \ref{sec:numericalexamples}

\section{Numerical examples}
\label{sec:numericalexamples}

For the numerical examples, we obtain forecast of the Treasury Bill rates among other macroeconomic variables, in a \textit{data-rich} environment. We use data from (cite Greene (20something)). Four of the time series are considered: the Treasury Bill rates, the real consumption, the consumer price index, and the real expenditure. They are all observed on a quaterly basis. We annualize the last three time series, but keep the Treasury Bill rates unchanged. So that, the four time series are nearly on the same scale.

%\newpage

\subsection{Descriptive statistics}

Figure \ref{all_series_plot} presents the resulting time series' data obtained after the few transformations described in the previous paragraph. Table \ref{tab:summary_four_ts} contains a summary of these data, where we can see that the four time series are now nearly expressed in the same scale.

\begin{figure}[!htb]
\centering
\includegraphics[width=10cm]{gfx/chapter-rvfl-ensembles/all_series.png}
\caption{Treasury Bills rates and transformed Real consumption, Real disposable income, and  Inflation data from (cite Greene et. al (2007)) in a \textit{data-rich} environment}
\label{all_series_plot}
\end{figure}


\begin{table}[!htb]
\begin{center}
% table caption is above the table
\caption{Summary statistics for the four transformed time series: Treasury Bills and transformed Real consumption, Real disposable income, and  Inflation data from (cite Greene et. al (2007))}
\label{tab:summary_four_ts}       % Give a unique label
% For LaTeX tables use
\begin{tabular}{llllllll}
\hline\noalign{\smallskip}
Series & Min & 1st Qrt  & Median  & Mean & 3rd Qrt  & Max & Std. Dev.\\
\noalign{\smallskip}\hline\noalign{\smallskip}
  Real consumption  & -11.990 & 1.814 & 3.637 & \textbf{3.513} & 5.414 & 19.978 & \textbf{3.546}\\
  Real disposable income  & -7.275 & 1.613 & 3.390 & \textbf{3.423} & 5.518 & 18.358 & \textbf{3.486}\\
  Inflation & -2.530  & 1.755 & 3.135 & \textbf{3.936} & 5.593 & 16.864 & \textbf{3.407}\\
  Treasury Bills rates & 0.810  & 3.138 & 5.050 & \textbf{5.270} & 6.715 & 15.090 & \textbf{2.829} \\
\noalign{\smallskip}\hline
\end{tabular}
\end{center}
\end{table}


\begin{table}
\begin{center}
% table caption is above the table
\caption{\textbf{Box-Pierce test for the independence} in the time series observations}
\label{tab:boxpierce}       % Give a unique label
% For LaTeX tables use
\begin{tabular}{llllll}
\hline\noalign{\smallskip}
Series &  \code{X-squared} & \code{p-value}  \\
\noalign{\smallskip}\hline\noalign{\smallskip}
  Real consumption & 0.0133 & \textbf{0.9082}  \\
  Real disposable income & 1.3912 & \textbf{0.2382} \\
  Inflation & 86.428 &  2.2e-16 \\
  Treasury Bills rates & 186.35 & 2.2e-16 \\
\noalign{\smallskip}\hline
\end{tabular}
\end{center}
\end{table}

\begin{figure}[!htb]
\centering
\includegraphics[width=12cm]{gfx/chapter-rvfl-ensembles/acf.png}
\caption{Autocorrelation function for the four times series: Treasury Bills rates, Real consumption, Real disposable income, Inflation}
\label{acf}
\end{figure}

\newpage

The Box-Pierce tests results presented in table \ref{tab:boxpierce}, and the autocorrelation functions presented in \ref{acf}, show that the two time series for Real consumption and Real disposable income could be considered as stationary after the transformations. Whereas for the Treasury Bills rates and Inflation, there is still a non-negligible autocorrelation within the series. 

\medskip

Another interesting information is given by figure \ref{corrplot}. We observe that the distribution of the data for inflation and Treasury Bills rates is skewed, when compared to the data for Real consumption and Real disposable income. 

\medskip

Also, based on the correlations displayed in figure \ref{corrplot}, the Real consumption is globally  decreasing when the Treasury Bills rates and the inflation are increasing. But when the Real disposable income increases, the Real consumption increases as well. 

\begin{figure}[!htb]
\centering
\includegraphics[width=14cm]{gfx/chapter-rvfl-ensembles/scatterplot.png}
\caption{Correlation plot for the four times series: Treasury Bills rates, Real consumption, Real disposable income, Inflation}
\label{corrplot}
\end{figure}

%\newpage

In sections \ref{bagging_example} and \ref{stacking_example}, we apply the bagging and stacking procedures described in sections \ref{sec:rvflbagging} and \ref{sec:rvflstacking} to the dataset we have just described. 


A rolling forecasting cross-validation method (see \cite{bergmeir2015note} and figure \ref{rolling_cv}). At the beginning of the procedure, the training set contains $12$ points ($4$ years), and the test set contains $4$ points(1 year). The training set is then advanced of one point forward (rolled), and the procedure is repeated until no more data for the training set are found.  

\begin{figure}[!htb]
\centering
\includegraphics[width=14cm]{gfx/chapter-rvfl-ensembles/rolling_cv.png}
\caption{Training and testing sets in rolling forecasting cross-validation}
\label{rolling_cv}
\end{figure}

We use the Root Mean Squared Error (RMSE) as a measure of the out-of-sample error. All the benchmarks are made on what is defined as \code{part3} in section \ref{sec:rvflstacking}, in order to have a similar perimeter for bagging and stacking. The results obtained by the ensembles are compared to those obtained by the base RVFL model. 

\subsection{Numerical example for bagging}
\label{bagging_example}

In this example, we use $B = 100$ resamples of the data, and calculate the average out-of-sample RMSE obtained by the ensemble model on all the testing sets (see figure \ref{rolling_cv}). The dataset used, is the one defined as \code{part3} in section \ref{sec:rvflstacking}.  

\subsection{Numerical example for stacking}
\label{stacking_example}

We calculate the average out-of-sample RMSE obtained by the ensemble model on all the testing sets (see figure \ref{rolling_cv}). The dataset used, is the one defined as \code{part3} in section \ref{sec:rvflstacking}.