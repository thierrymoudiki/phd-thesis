% !TEX root = ../thesis-example.tex
%
\chapter{Introduction}
\label{sec:intro}

\section{Motivation and Problem Statement}
\label{sec:intro:motivation}

The Own Risk Solvency and Assessment (ORSA) is a set of processes defined in the European prudential directive Solvency II, that serve for decision-making and strategic analysis. In the context of ORSA, insurance companies are required to assess their solvency needs in a continuous and prospective way. For this purpose, they notably need to forecast their balance sheet -asset and liabilities- over a defined horizon. 

Here, we specifically focus on the assets' forecasting part. \textbf{This thesis is about the Yield Curve, Forecasting, and Forecasting the Yield Curve}. We present a few novel techniques for the construction, the extrapolation of static curves (that is, curves which are constructed at a fixed date), and for forecasting the spot interest rates over time. 

Throughout the text, when we say 'Yield Curve', we actually mean 'Discount curve'. That is: we ignore the counterparty credit risk, and consider that the curves are \textit{risk-free}. Though, the same techniques could be applied to construct/forecast the actual \textit{risk-free} curves and credit spreads' curves, and combine both to obtain pseudo-discount curves incorporating the counterparty credit risk. 

The structure of the thesis is described in section \ref{sec:intro:structure}. 

\section{Thesis Structure}
\label{sec:intro:structure}

\textbf{Chapter \ref{sec:insurance_swap_curve}} \\[0.2em]
We derived a class of discount curve construction and extrapolation methods,  based on a class of interest rate models called \textit{exogenous short-rate models}. That means: constructing a static Yield Curve at a given date, by using some specific financial instruments with different maturities quoted at this date. Then, defining what are the discount rates beyond the longest maturity observed for these financial instruments. The extrapolated part of the curve is typically necessary for the pricing of long-term insurance liabilities. In the framework that we propose, Yield Curve forecasts can be obtained by using a \textbf{functional principal components analysis} on the model parameters.

\textbf{Chapter \ref{sec:rvfl_mts}} \\[0.2em]
We are interested in obtaining forecasts for multiple time series, by taking into account the potential nonlinear relationships between their observations. For this purpose, we used a specific type of regression model on an augmented dataset of lagged time series. Our model is inspired by dynamic regression models, with the response variable's lags included as predictors, and is known as \textbf{random vector functional link (RVFL) neural networks}. The RVFL neural networks have been successfully applied in the past, to solving regression and classification problems. The novelty of our approach is to apply an RVFL model to multivariate time series, under two separate regularization constraints on the regression parameters.

\textbf{Chapter \ref{sec:rvfl_ensembles}} \\[0.2em]
The goal of ensemble learning is to combine two or more statistical/machine learning models - the base learners - into one, in order to obtain an ensemble model. The ensemble model is expected to have an improved out-of-sample error over the base models. We apply two popular ensemble learning methods to multiple time series forecasting: \textbf{bootstrap aggregating}, known as bagging, \textbf{boosting}, and \textbf{stacked generalization}, known as stacking. The base learners that we use, are the RVFL introduced in the previous paragraph.

\textbf{Chapter \ref{sec:discount_curve_krls}} \\[0.2em]
\textbf{Kernel regularized least squares} (KRLS) learning methods are applied to Yield Curve forecasting. Two types of formulations of the forecasting problem are tested. One relying on a popular framework called Dynamic Nelson-Siegel, and another one, in which we apply the KRLS directly to the explain the spot rates (response variable) as a function of the observation dates and time to maturities (covariates).

\textbf{Chapter \ref{sec:bayesian_rvfl}} \\[0.2em]
We present a \textbf{bayesian quasi-randomized vector functional link neural network model} (BQRVFL), with one hidden layer. It's a penalized regression model on an augmented data set, in which we assume that a prior multivariate gaussian distribution governs the regression parameters. The BQRVFL model is presented, along with the associated formulas for confidence interval around its predictions. It is then applied as a workhorse for \textbf{bayesian optimization} of machine learning cross-validation functions. The machine learning cross-validation functions that we consider are those associated to the selection of hyperparameters of RVFL and KRLS models.
