% !TEX root = ../thesis-example.tex
%
\chapter{Conclusion}
\label{sec:conclusion}

In this thesis, in chapter \ref{sec:insurance_swap_curve}, we derived a class of discount curve construction and extrapolation methods,  based on a class of interest rate models called \textit{exogenous short-rate models}. Then, in chapter \ref{sec:rvfl_mts} we dealt with the obtainment of forecasts for multiple time series, by taking into account the potential nonlinear relationships between their observations. We presented a specific type of neural networks learning technique to forecast the Yield Curve, and obtain \textit{stressed} versions of the forecasts. Chapter \ref{sec:rvfl_ensembles} was about combining multiple forecasting techniques, in search for an improved out-of-sample performance. The basis for these ensemble models were the individual models presented in chapter \ref{sec:rvfl_mts}, and we indeed obtained a better performance with the ensembles. Chapter \ref{sec:discount_curve_krls} was about forecasting techniques based on \textit{kernels}. The idea of learning with kernels is to assign a high covariance to observations that are close to each other, and conversely a low covariance to observations that are far from each other. The response variable can be explained as a linear combination of similiarities/dissimilarities between the observations. In the final chapter, we compared the out-of-sample performances of the models derived in chapter \ref{sec:rvfl_mts} and  \ref{sec:discount_curve_krls}, by using bayesian optimization. The methods based on kernels are extremely competitive, at the expense of being more demanding in resources. It would be interesting in the future to try out alternative activation functions/simulation for the hidden nodes/feature scaling in models from chapter \ref{sec:rvfl_mts}, and see how these choices affect their performances. The model from chapter \ref{sec:rvfl_mts} also \textit{scales} well, so it would be interesting to see how it performs on thousands of time series. 